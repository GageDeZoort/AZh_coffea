{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e73ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import uproot\n",
    "from coffea import processor, util\n",
    "from coffea.lumi_tools import LumiMask\n",
    "from coffea.nanoevents import NanoAODSchema, NanoEventsFactory\n",
    "\n",
    "from azh_analysis.processors.analysis_processor import AnalysisProcessor\n",
    "from azh_analysis.utils.btag import get_btag_SFs, get_btag_tables\n",
    "from azh_analysis.utils.corrections import (\n",
    "    dyjets_stitch_weights,\n",
    "    get_electron_ES_weights,\n",
    "    get_electron_ID_weights,\n",
    "    get_electron_trigger_SFs,\n",
    "    get_fake_rates,\n",
    "    get_muon_ES_weights,\n",
    "    get_muon_ID_weights,\n",
    "    get_muon_trigger_SFs,\n",
    "    get_pileup_weights,\n",
    "    get_tau_ID_weights,\n",
    ")\n",
    "from azh_analysis.utils.sample import get_fileset, get_nevts_dict, get_sample_info\n",
    "\n",
    "# setup logging\n",
    "log_format = \"%(asctime)s %(levelname)s %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=log_format)\n",
    "logging.info(\"Initializing\")\n",
    "\n",
    "# relevant parameters\n",
    "year, source = '2017', 'MC_UL'\n",
    "\n",
    "# load up golden jsons\n",
    "golden_json_dir = \"../samples/data_certification\"\n",
    "golden_jsons = {\n",
    "    \"2018\": join(golden_json_dir, \"data_cert_2018.json\"),\n",
    "    \"2017\": join(golden_json_dir, \"data_cert_2017.json\"),\n",
    "    \"2016postVFP\": join(golden_json_dir, \"data_cert_2016.json\"),\n",
    "    \"2016preVFP\": join(golden_json_dir, \"data_cert_2016.json\"),\n",
    "}\n",
    "lumi_masks = {year: LumiMask(golden_json) for year, golden_json in golden_jsons.items()}\n",
    "\n",
    "# load up fake rates\n",
    "fr_base = f\"../corrections/fake_rates/UL_{year}\"\n",
    "fake_rates = get_fake_rates(fr_base, year)\n",
    "logging.info(f\"Using fake rates\\n{fr_base}\")\n",
    "\n",
    "# load up electron / muon / tau IDs\n",
    "eID_base = f\"../corrections/electron_ID/UL_{year}\"\n",
    "eID_file = join(\n",
    "    eID_base, f\"Electron_RunUL{year}_IdIso_AZh_IsoLt0p15_IdFall17MVA90noIsov2.root\"\n",
    ")\n",
    "\n",
    "eIDs = get_electron_ID_weights(eID_file)\n",
    "logging.info(f\"Using eID_SFs:\\n{eID_file}\")\n",
    "\n",
    "eES_SFs = get_electron_ES_weights(\"../corrections/electron_ES/\", year)\n",
    "logging.info(f\"Using eES_SFs from corrections/ele_ES/UL_{year}\")\n",
    "\n",
    "mES_SFs = get_muon_ES_weights(\"../corrections/muon_ES/\", year)\n",
    "logging.info(f\"Using mES_SFs from corrections/muon_ES/UL_{year}\")\n",
    "\n",
    "mID_base = f\"../corrections/muon_ID/UL_{year}\"\n",
    "mID_file = join(mID_base, f\"Muon_RunUL{year}_IdIso_AZh_IsoLt0p15_IdLoose.root\")\n",
    "mIDs = get_muon_ID_weights(mID_file)\n",
    "logging.info(f\"Using mID_SFs:\\n{mID_file}\")\n",
    "\n",
    "tID_base = f\"../corrections/tau_ID/UL_{year}\"\n",
    "tID_file = join(tID_base, \"tau.corr.json\")\n",
    "tIDs = get_tau_ID_weights(tID_file)\n",
    "logging.info(f\"Using tID_SFs:\\n{tID_file}\")\n",
    "\n",
    "# load up electron / muon trigger SFs\n",
    "e_trigs = {\n",
    "    \"2016preVFP\": \"Ele25_EtaLt2p1\",\n",
    "    \"2016postVFP\": \"Ele25_EtaLt2p1\",\n",
    "    \"2017\": \"Ele35\",\n",
    "    \"2018\": \"Ele35\",\n",
    "}\n",
    "e_trig_base = f\"../corrections/electron_trigger/UL_{year}\"\n",
    "e_trig_file = join(e_trig_base, f\"Electron_RunUL{year}_{e_trigs[year]}.root\")\n",
    "e_trig_SFs = get_electron_trigger_SFs(e_trig_file)\n",
    "\n",
    "m_trigs = {\n",
    "    \"2016preVFP\": \"IsoMu24orIsoTkMu24\",\n",
    "    \"2016postVFP\": \"IsoMu24orIsoTkMu24\",\n",
    "    \"2017\": \"IsoMu27\",\n",
    "    \"2018\": \"IsoMu27\",\n",
    "}\n",
    "m_trig_base = f\"../corrections/muon_trigger/UL_{year}\"\n",
    "m_trig_file = join(m_trig_base, f\"Muon_RunUL{year}_{m_trigs[year]}.root\")\n",
    "m_trig_SFs = get_muon_trigger_SFs(m_trig_file)\n",
    "\n",
    "# load up btagging tables\n",
    "btag_root = \"../corrections/btag/\"\n",
    "btag_tables = get_btag_tables(btag_root, f\"{year}\", UL=True)\n",
    "btag_SFs = get_btag_SFs(btag_root, f\"{year}\", UL=True)\n",
    "\n",
    "# load up non-signal MC csv / yaml files\n",
    "fset_string = f\"{source}_{year}\"\n",
    "sample_info = get_sample_info(join(\"../samples\", fset_string + \".csv\"))\n",
    "fileset = get_fileset(join(\"../samples/filesets\", fset_string + \".yaml\"))\n",
    "pileup_weights = None\n",
    "if \"MC\" in source or \"signal\" in source:\n",
    "    pileup_weights = get_pileup_weights(\"../corrections/pileup/\", year=year)\n",
    "\n",
    "# only run over root files\n",
    "for sample, files in fileset.items():\n",
    "    good_files = []\n",
    "    for f in files:\n",
    "        if f.split(\".\")[-1] == \"root\":\n",
    "            good_files.append(f)\n",
    "    fileset[sample] = good_files\n",
    "logging.info(f\"running on\\n {fileset.keys()}\")\n",
    "\n",
    "# extract the sum_of_weights from the ntuples\n",
    "nevts_dict, dyjets_weights = None, None\n",
    "\n",
    "if \"MC\" in source:\n",
    "    nevts_dict = get_nevts_dict(fileset, year)\n",
    "    print(\"fileset keys\", fileset.keys())\n",
    "    if f\"DYJetsToLLM-50_{year}\" in fileset.keys():\n",
    "        dyjets_weights = dyjets_stitch_weights(sample_info, nevts_dict, year)\n",
    "        \n",
    "# load up signal MC csv / yaml files\n",
    "fileset = {k: v for k, v in fileset.items() if \"ZHHToWW\" in k}\n",
    "\n",
    "logging.info(f\"Successfully built sum_of_weights dict:\\n {nevts_dict}\")\n",
    "logging.info(f\"Successfully built dyjets stitch weights:\\n {dyjets_weights}\")\n",
    "\n",
    "# start timer, initiate cluster, ship over files\n",
    "tic = time.time()\n",
    "\n",
    "# instantiate processor module\n",
    "proc_instance = AnalysisProcessor(\n",
    "    source=source,\n",
    "    year=year,\n",
    "    sample_info=sample_info,\n",
    "    fileset=fileset,\n",
    "    pileup_weights=pileup_weights,\n",
    "    lumi_masks=lumi_masks,\n",
    "    nevts_dict=nevts_dict,\n",
    "    eleID_SFs=eIDs,\n",
    "    eleES_SFs=eES_SFs,\n",
    "    muID_SFs=mIDs,\n",
    "    muES_SFs=mES_SFs,\n",
    "    tauID_SFs=tIDs,\n",
    "    e_trig_SFs=e_trig_SFs,\n",
    "    m_trig_SFs=m_trig_SFs,\n",
    "    fake_rates=fake_rates,\n",
    "    dyjets_weights=dyjets_weights,\n",
    "    btag_eff_tables=btag_tables[0],\n",
    "    btag_SFs=btag_SFs,\n",
    "    btag_pt_bins=btag_tables[1],\n",
    "    btag_eta_bins=btag_tables[2],\n",
    "    run_fastmtt=True,\n",
    "    systematic=\"all\",\n",
    "    same_sign=False,\n",
    "    blind=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef674ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137ea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures_run = processor.Runner(\n",
    "    executor=processor.FuturesExecutor(compression=None, workers=1),\n",
    "    schema=NanoAODSchema,\n",
    ")\n",
    "\n",
    "out = futures_run(\n",
    "    fileset,\n",
    "    \"Events\",\n",
    "    processor_instance=proc_instance,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[\"m4l\"][\"GluGluZHHToWW\"][::sum, ::sum, ::sum, \"tauID_11_down\", \"cons\", :].values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_rate = False\n",
    "proc_instance = AnalysisProcessor(sample_info=sample_info,\n",
    "                                  pileup_tables=pileup_tables,\n",
    "                                  lumi_masks=lumi_masks,\n",
    "                                  nevts_dict=nevts_dict,\n",
    "                                  high_stats=True,\n",
    "                                  eleID_SFs=eIDs, muID_SFs=mIDs, tauID_SFs=tIDs,\n",
    "                                  fake_rates=fake_rates,\n",
    "                                  dyjets_weights=dyjets_weights,\n",
    "                                  e_trig_SFs=e_trig_SFs, m_trig_SFs=m_trig_SFs,\n",
    "                                  btag_eff_tables=btag_eff_tables, btag_SFs=btag_SFs,\n",
    "                                  btag_pt_bins=btag_pt_bins, btag_eta_bins=btag_eta_bins,\n",
    "                                  run_fastmtt=True, fill_hists=True)\n",
    "\n",
    "if fake_rate: \n",
    "    proc_instance = SS4lFakeRateProcessor(sample_info=sample_info,\n",
    "                                          pileup_tables=pileup_tables,\n",
    "                                          mode='tt',\n",
    "                                          nevts_dict=nevts_dict,\n",
    "                                          lumi_masks=lumi_masks,\n",
    "                                          high_stats=True,\n",
    "                                          eleID_SFs=eIDs,\n",
    "                                          muID_SFs=mIDs,\n",
    "                                          tauID_SFs=tIDs,\n",
    "                                          dyjets_weights=dyjets_weights,\n",
    "                                          e_trig_SFs=e_trig_SFs, m_trig_SFs=m_trig_SFs)\n",
    "    to\n",
    "out = processor.run_uproot_job(\n",
    "        fileset ,\n",
    "        treename=\"Events\",\n",
    "        processor_instance=proc_instance,\n",
    "        executor=processor.futures_executor,\n",
    "        executor_args={\"schema\": NanoAODSchema, 'workers': 1},\n",
    "        chunksize=25000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ec41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hist\n",
    "\n",
    "base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/DY4JetsToLLM-50'\n",
    "file = join(base, 'all_DY4JetsToLLM-50_file001_part_1of3_Electrons.root')\n",
    "events = NanoEventsFactory.from_root(file, schemaclass=NanoAODSchema).events()\n",
    "met = events.MET\n",
    "tau = events.Tau\n",
    "ele = events.Electron\n",
    "mu = events.Muon\n",
    "\n",
    "dataset_axis = hist.axis.StrCategory(name=\"dataset\", label=\"\", categories=[], growth=True)\n",
    "pt_axis = hist.axis.Regular(name=\"pt\", label=r\"$p_T$ [GeV]\", bins=25, start=0, stop=250 )\n",
    "cat_axis = hist.axis.StrCategory(name=\"category\", label=\"\", categories=[], growth=True)\n",
    "dummy_axis = hist.axis.StrCategory(name=\"dummy\", label=\"\",  categories=[], growth=True)\n",
    "output = hist.Hist(dataset_axis, pt_axis, cat_axis, dummy_axis)\n",
    "\n",
    "N = 1000\n",
    "tt = ak.cartesian({'t1': ele[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(ele[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "eeet = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "eeet = eeet[(ak.argmax(eeet.tt.t1.pt, axis=1, keepdims=True))]\n",
    "eeet = eeet[~ak.is_none(eeet, axis=1)]\n",
    "tt = ak.cartesian({'t1': mu[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(ele[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "eemt = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "eemt = eemt[(ak.argmax(eemt.tt.t1.pt, axis=1, keepdims=True))]\n",
    "eemt = eemt[~ak.is_none(eemt, axis=1)]\n",
    "eeet['category'] = 'eeet'\n",
    "eemt['category'] = 'eemt'\n",
    "eeet['weights'] = 0.8*np.ones(len(eeet))\n",
    "eemt['weights'] = 0.9*np.ones(len(eemt))\n",
    "cands = {'eeet': eeet, 'eemt': eemt}\n",
    "lltt = ak.concatenate(list(cands.values()), axis=1)\n",
    "lltt = lltt[ak.num(lltt)==1]\n",
    "output.fill(dataset='test', pt=np.array(ak.flatten(lltt.ll.l1.pt)), \n",
    "            category=ak.to_numpy(ak.flatten(lltt.category)),\n",
    "            dummy='nom', weight=ak.to_numpy(ak.flatten(lltt.weights)))\n",
    "output.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e3a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea import analysis_tools\n",
    "\n",
    "base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/DY4JetsToLLM-50'\n",
    "file = join(base, 'all_DY4JetsToLLM-50_file001_part_1of3_Electrons.root')\n",
    "events = NanoEventsFactory.from_root(file, schemaclass=NanoAODSchema).events()\n",
    "\n",
    "ele = events.Electron\n",
    "met = events.MET\n",
    "tau = events.Tau\n",
    "mu = events.Muon\n",
    "jet = events.Jet\n",
    "\n",
    "N=100\n",
    "tt = ak.cartesian({'t1': ele[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(ele[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "eeet = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "eeet = eeet[(ak.argmax(eeet.tt.t1.pt, axis=1, keepdims=True))]\n",
    "tt = ak.cartesian({'t1': mu[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(ele[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "eemt = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "eemt = eemt[(ak.argmax(eemt.tt.t1.pt, axis=1, keepdims=True))]\n",
    "lltt_cats = {'eemt': eemt, 'eeet': eeet}\n",
    "\n",
    "def apply_lepton_ID_SFs(lltt, cat, is_data=False):\n",
    "    l1, l2 = lltt['ll']['l1'], lltt['ll']['l2']\n",
    "    t1, t2 = lltt['tt']['t1'], lltt['tt']['t2']\n",
    "\n",
    "    # e/mu scale factors\n",
    "    if cat[:2] == 'ee':\n",
    "        l1_w = lepton_ID_weight(l1, 'e', eIDs, is_data)\n",
    "        l2_w = lepton_ID_weight(l2, 'e', eIDs, is_data)\n",
    "    elif cat[:2] == 'mm':\n",
    "        l1_w = lepton_ID_weight(l1, 'm', mIDs, is_data)\n",
    "        l2_w = lepton_ID_weight(l2, 'm', mIDs, is_data)\n",
    "\n",
    "    # also consider hadronic taus\n",
    "    if cat[2:] == 'em':\n",
    "        t1_w = lepton_ID_weight(t1, 'e', eIDs, is_data)\n",
    "        t2_w = lepton_ID_weight(t2, 'm', mIDs, is_data)\n",
    "    elif cat[2:] == 'et':\n",
    "        t1_w = lepton_ID_weight(t1, 'e', eIDs, is_data)\n",
    "        t2_w = tau_ID_weight(t2, tIDs, cat)\n",
    "    elif cat[2:] == 'mt':\n",
    "        t1_w = lepton_ID_weight(t1, 'm', mIDs, is_data)\n",
    "        t2_w = tau_ID_weight(t2, tIDs, cat)\n",
    "    elif cat[2:] == 'tt':\n",
    "        t1_w = tau_ID_weight(t1, tIDs, cat)\n",
    "        t2_w = tau_ID_weight(t2, tIDs, cat)\n",
    "\n",
    "    # apply ID scale factors\n",
    "    return l1_w * l2_w * t1_w * t2_w\n",
    "\n",
    "weights = analysis_tools.Weights(len(events), storeIndividual=True)\n",
    "for cat, lltt in lltt_cats.items(): \n",
    "    lltt = lltt[~ak.is_none(lltt, axis=1)]\n",
    "    lltt = ak.fill_none(lltt, [], axis=0)\n",
    "    flat, num = ak.flatten(lltt), ak.num(lltt)\n",
    "    w = apply_lepton_ID_SFs(flat, cat)\n",
    "    w = ak.unflatten(w, num)\n",
    "    \n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/DY4JetsToLLM-50'\n",
    "file = join(base, 'all_DY4JetsToLLM-50_file001_part_1of3_Electrons.root')\n",
    "events = NanoEventsFactory.from_root(file, schemaclass=NanoAODSchema).events()\n",
    "#base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/SingleMuon_Run2018A'\n",
    "#file = join(base, 'all_SingleMuon_Run2018A_file038_part_2of3_Muons.root')\n",
    "#events = NanoEventsFactory.from_root(file, schemaclass=NanoAODSchema).events()\n",
    "#tag0 = ak.Array(t1.layout.content.project(1)\n",
    "    \n",
    "#l1 = cands.ll.l1\n",
    "#l1_tags = np.asarray(l1.layout.content.tags)\n",
    "#for tag in np.unique(l1_tags):\n",
    "##    tags = l1.layout.content.project(tag)\n",
    " #   ID = tags.content.parameter(\"__record__\")\n",
    "\n",
    "#for cat in ['eemt', 'eeet', 'mmet']:\n",
    "#    l1 = cands.ll.l1[cands.category==cat]\n",
    "#    print(ak.type(l1))\n",
    "#    l1 = l1.layout.content.project(0)\n",
    "#    print(l1)\n",
    "    \n",
    "#cands = ak.concatenate([lltt_eemt, lltt_eeet], axis=1)\n",
    "#print('cands', ak.num(cands))\n",
    "#tags = np.asarray(cands.layout.content.tags)\n",
    "#print(tags)\n",
    "#for tag in np.unique(tags):\n",
    "#    mask = (tags==tag)\n",
    "#    print(np.asarray(cands.layout.content.project(tag)))\n",
    "#    \n",
    "#ele = ak.Array(leptons.layout.content.project(0))\n",
    "#print(ele.dEsigmaUp)\n",
    "\n",
    "ele = events.Electron\n",
    "met = events.MET\n",
    "tau = events.Tau\n",
    "mu = events.Muon\n",
    "jet = events.Jet\n",
    "\n",
    "N=10**6\n",
    "tt = ak.cartesian({'t1': ele[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(ele[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "eeet = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "eeet = eeet[(ak.argmax(eeet.tt.t1.pt, axis=1, keepdims=True))]\n",
    "tt = ak.cartesian({'t1': mu[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(ele[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "eemt = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "eemt = eemt[(ak.argmax(eemt.tt.t1.pt, axis=1, keepdims=True))]\n",
    "tt = ak.cartesian({'t1': ele[:N], 't2': tau[:N]}, axis=1)\n",
    "ll = ak.combinations(mu[:N], 2, axis=1, fields=['l1', 'l2'])\n",
    "mmet = ak.cartesian({'tt': tt, 'll': ll}, axis=1)\n",
    "mmet = mmet[(ak.argmax(mmet.tt.t1.pt, axis=1, keepdims=True))]\n",
    "print('eeet', ak.sum(ak.num(eeet)))\n",
    "print('eemt', ak.sum(ak.num(eemt)))\n",
    "print('mmet', ak.sum(ak.num(mmet)))\n",
    "eemt[\"category\"] = 'eemt'\n",
    "eeet[\"category\"] = 'eeet'\n",
    "mmet[\"category\"] = 'mmet'\n",
    "#cands = ak.concatenate([eemt, eeet, mmet], axis=1)\n",
    "cands = eemt\n",
    "cands['met'] = met[:N]\n",
    "cands = cands[~ak.is_none(cands, axis=1)]\n",
    "cands = cands[ak.num(cands)>0]    \n",
    "print(cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def apply_eleES(ele, met, syst='nom'):\n",
    "    if (syst=='nom'):\n",
    "        return ele, met\n",
    "    t0 = time()\n",
    "    pt, eta = ele.pt, ele.eta\n",
    "    phi, mass = ele.phi, ele.mass\n",
    "    in_barrel = (abs(eta) < 1.479)\n",
    "    in_crossover = ((abs(eta) > 1.479) & (abs(eta) < 1.653))\n",
    "    in_endcap = (abs(eta) > 1.653)\n",
    "    barrel_shifts = {'up': 1.03, 'down': 0.97}\n",
    "    crossover_shifts = {'up': 1.04, 'down': 0.96}\n",
    "    endcap_shifts = {'up': 1.05, 'down': 0.95}\n",
    "    weights = (in_barrel * barrel_shifts[syst] +\n",
    "               in_crossover * crossover_shifts[syst] +\n",
    "               in_endcap * endcap_shifts[syst])\n",
    "    ele_p4 = ak.zip({'pt': ele.pt, 'eta': ele.eta,\n",
    "                     'phi': ele.phi, 'mass': ele.mass},\n",
    "                     with_name='PtEtaPhiMLorentzVector')\n",
    "    ele_p4_shift = (weights * ele_p4)\n",
    "    ele_x_diff = (1-weights) * ele.pt * np.cos(ele.phi)\n",
    "    ele_y_diff = (1-weights) * ele.pt * np.sin(ele.phi)\n",
    "    met_x = met.pt * np.cos(met.phi) + ele_x_diff\n",
    "    met_y = met.pt * np.sin(met.phi) + ele_y_diff\n",
    "    met_p4 = ak.zip({'x': met_x, 'y': met_y,\n",
    "                     'z': 0, 't': 0}, with_name='LorentzVector')\n",
    "    met['pt'] = met_p4.pt\n",
    "    met['phi'] = met_p4.phi\n",
    "    return ele_p4_shift, met\n",
    "\n",
    "def apply_eleSmear(ele, met, syst='nom'):\n",
    "    if (syst=='nom'):\n",
    "        return ele, met\n",
    "    shift = ele.dEsigmaUp if (syst=='up') else ele.dEsigmaDown\n",
    "    weights = shift + 1.0\n",
    "    ele_p4 = ak.zip({'pt': ele.pt, 'eta': ele.eta,\n",
    "                     'phi': ele.phi, 'mass': ele.mass},\n",
    "                    with_name='PtEtaPhiMLorentzVector')\n",
    "    ele_p4_shift = (weights * ele_p4)\n",
    "    ele_x_diff = (1-weights) * ele.pt * np.cos(ele.phi)\n",
    "    ele_y_diff = (1-weights) * ele.pt * np.sin(ele.phi)\n",
    "    met_x = met.pt * np.cos(met.phi) + ele_x_diff\n",
    "    met_y = met.pt * np.sin(met.phi) + ele_y_diff\n",
    "    met_p4 = ak.zip({'x': met_x, 'y': met_y,\n",
    "                     'z': 0, 't': 0}, with_name='LorentzVector')\n",
    "    met['pt'] = met_p4.pt\n",
    "    met['phi'] = met_p4.phi\n",
    "    return ele_p4_shift, met_p4\n",
    "\n",
    "print(ele.pt)\n",
    "ele_new, met_new = apply_eleSmear(cands.ll.l1, cands.met, 'up')\n",
    "print(ele_new.pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd578c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[55.8], [71.7], [44.4, 41.4], [68.5, ... 62.7, 20.5], [85.3, 28.4], [99.1, 22.1]]\n",
    "1: 0.03943324089050293\n",
    "2: 0.10126161575317383\n",
    "3: 0.12982583045959473\n",
    "4: 0.17160296440124512\n",
    "[[42.2], [65.1], [53.5], [174], [43.9], ... 48.9], [105, 105], [147], [82.7], [96.1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e50f42",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_eleES(ele, met, eleES_shift='nom', eleSmear_shift='nom'):\n",
    "    # decide ES weights by region of the detector\n",
    "    in_barrel = (abs(ele.eta) < 1.479)\n",
    "    in_crossover = ((abs(ele.eta) > 1.479) & (abs(ele.eta) < 1.653))\n",
    "    in_endcap = (abs(ele.eta) > 1.653)\n",
    "    barrel_shifts = {'up': 1.03, 'nom': 1.0, 'down': 0.97}\n",
    "    crossover_shifts = {'up': 1.04, 'nom': 1.0, 'down': 0.96}\n",
    "    endcap_shifts = {'up': 1.05, 'nom': 1.0, 'down': 0.95}\n",
    "    eleES_weights = (in_barrel * barrel_shifts[eleES_shift] +\n",
    "                     in_crossover * crossover_shifts[eleES_shift] +\n",
    "                     in_endcap * endcap_shifts[eleES_shift])\n",
    "\n",
    "    # get smearing weights\n",
    "    if eleSmear_shift=='nom':\n",
    "        shift = 0\n",
    "    else:\n",
    "        shift = ele.dEsigmaUp if (eleSmear_shift=='up') else ele.dEsigmaDown\n",
    "    eleSmear_weights = shift + 1.0\n",
    "\n",
    "    ele_p4 = ak.zip({'pt': ele.pt, 'eta': ele.eta,\n",
    "                     'phi': ele.phi, 'mass': ele.mass},\n",
    "                     with_name='PtEtaPhiMLorentzVector')\n",
    "\n",
    "    # apply weights\n",
    "    weights = eleES_weights * eleSmear_weights\n",
    "    ele_p4_shift = (weights * ele_p4)\n",
    "    ele_x_diff = (1-weights) * ele.pt * np.cos(ele.phi)\n",
    "    ele_y_diff = (1-weights) * ele.pt * np.sin(ele.phi)\n",
    "    diffs = {'x': ele_x_diff, 'y': ele_y_diffs}\n",
    "    return ele_p4_shift, diffs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "met_x = met.pt * np.cos(met.phi) + ele_x_diff\n",
    "    met_y = met.pt * np.sin(met.phi) + ele_y_diff\n",
    "    met_p4 = ak.zip({'x': met_x, 'y': met_y,\n",
    "                     'z': 0, 't': 0}, with_name='LorentzVector')\n",
    "    met['pt'] = met_p4.pt\n",
    "    met['phi'] = met_p4.phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff34d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f9d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/eos/uscms/store/group/lpcsusyhiggs/ntuples/AZh/nAODv9/2018/BBAToZhToLLTauTauM325'\n",
    "file = join(base, 'all_BBAToZhToLLTauTauM325_file006_part_1of3_Electrons.root')\n",
    "events = NanoEventsFactory.from_root(file, schemaclass=NanoAODSchema).events()\n",
    "taus = events.Tau\n",
    "taus = ak.flatten(taus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07b3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "from azh_analysis.utils.corrections import get_tau_ID_weights, tau_ID_weight\n",
    "\n",
    "tID_base = f\"../corrections/tau_ID/UL_{year}\"\n",
    "tID_file = join(tID_base, \"tau.corr.json\")\n",
    "tIDs = get_tau_ID_weights(tID_file)\n",
    "tau_ID_weight(taus, tIDs, \"eett\", syst=\"nom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40d3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/uscms_data/d3/jdezoort/AZh_columnar/CMSSW_10_2_9/src/azh_coffea/src/corrections/temp\"\n",
    "for f in os.listdir(base):\n",
    "    vs_e, vs_j = f.split(\"_\")[-2], f.split(\"_\")[-3]\n",
    "    f = uproot.open(join(base, f))\n",
    "    for k in f.keys():\n",
    "        ks = k.split(\"_\"-)\n",
    "        dm, year = ks[0], ks[1]\n",
    "        if \"2016\" in year: \n",
    "            year = year + ks[2]\n",
    "        else:\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca8e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from azh_analysis.utils.corrections import get_tau_ID_weights\n",
    "tID_base = f\"../corrections/tau_ID/UL_{year}\"\n",
    "tID_file = join(tID_base, \"tau.corr.json\")\n",
    "tIDs = get_tau_ID_weights(tID_file)\n",
    "print([k for k in tIDs.keys()])\n",
    "print(tIDs[\"DeepTau2017v2p1VSe\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8dc91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c482533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azh_analysis.utils.btag import get_btag_SFs, get_btag_tables\n",
    "btag_root = \"../corrections/btag/\"\n",
    "btag_tables = get_btag_tables(btag_root, f\"{year}\", UL=True)\n",
    "btag_SFs = get_btag_SFs(btag_root, f\"{year}\", UL=True)\n",
    "print([k for k in btag_tables[0].keys() if \"ZZ\" in k])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
